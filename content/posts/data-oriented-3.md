---
title: データ指向アプリケーションデザインメモ3
date: "2019-09-22T11:00:00.000Z"
template: "post"
draft: false
slug: "/posts/data-oriented-3/"
category: "daily"
tags:
  - "study"
description: "読書ログ"
---

## このページについて

データ指向アプリケーションデザイン読書の記録をつらつらと書いておく

## 10章 バッチ処理

**unixの哲学(簡易)**

- プログラムは1つのことだけをうまくこなすようにする
- プログラムは他の未知のプログラムの入力となることを想定する
  - 例としては、パイプでつなげるよう、出力は標準出力に書き込む
- ソフトウェアはせいぜい数週間いないに作れるものをスコープとしておく
- 手作業をしない。使い捨てになろうとツールを使う

**MapReduce**

ジョブは1つ以上の入力をとり、1つ以上の出力を生成する。入力データへの副作用はない。
プログラミングフレームワーク
ある入力(レコード)に対して、開発者が定義した key-value の値やソートを生成する処理を行う(**mapper**)
mapperによって生成されたデータに対する処理を行うのが **reducer**  
プログラマは上記2つのロジックを実装してデータパイプランを作る  

@Todo HDFSって今もポピュラー?基本的にHadoopとはセット?

**バッチ処理設計(MapReduce)の注意**

ある処理においてなるべくネットワーク越しの通信を行わない。ローカルで処理が完結するのが望ましい。  
なので参照系データもなるべくローカルに寄せる仕組みが必要。(ETLプロセス用意など)
また、MapReduce処理の出力としては、prod環境のDBなどここでもネットワーク越しに逐次書き込みを行う設計は避ける  
その代わり、新しいデータベースをバッチジョブで作成し、分散ファイルシステム中のジョブの出力ディレクトリに書き出す  
書き出したものは頃合いを見て、参照系を扱うサーバへバルクロードする
こういったデータベースは基本リードオンリーとなっていて、データインポート中には過去の値を返し、インポート後にはアトミックに値を書き換えるといった機能が提供されている(Voldemortの場合)。基本ジョブが最初に書き込んだデータに対してのみ動き、immutableを守るようにできている
データソースをimmutableに保つので、なにか途中でロールバックせざるを得ないときもやり直しをすれば、データソースが変わっていなければMapReduceは結果整合性を保てる。

**MapReduceの先**

Spark, Tez, Flink のような データフローエンジン  
ワークフロー全体を一つのジョブとして定義できる。これまでは、mapperとreducerで細かく分割してきたが、それではある最終アウトプットの途中でのジョブの結果は他のジョブからは参照されないことが多々ある。そういったデータ(中間状態)を実体化するのは too much なので上記のような仕組みが考え出された。(例えば、中間状態をレプリケーションすること) またタスクの依存による待ちが発生してしまっている状況ももったいない。実は、reducerが出力した内容をreducerが受け取ればmapperは不要だったりする。
@Todo Tezとか分散フレームワークはどれが人気なのかgoogle trendsで検索ワード比較してみる

**Pregelモデル**
googleの論文が発祥。ある頂点は別の頂点にメッセージが送れる、グラフ構造のような作りをしている。
そのため、どのようにでもパーティショニングが可能。グラフだからといってあんまり分散させるとマシン間での  
送受信オーバーヘッドはそれないになってくる
@Todo もうちょっとメリデメ調べる

## 11章 ストリーム処理